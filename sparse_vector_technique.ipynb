{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Some useful utilities\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "def z_clip(xs, b):\n",
    "    return [min(x, b) for x in xs]\n",
    "\n",
    "def clip(xs, upper, lower):\n",
    "    return [max(min(x, upper), lower) for x in xs]\n",
    "\n",
    "def your_code_here():\n",
    "    return 1\n",
    "\n",
    "def test(msg, value, expected):\n",
    "    if value == expected:\n",
    "        print(f\"{msg}: {value}, as expected\")\n",
    "    else:\n",
    "        print(f\"{msg}: OH NO! Got {value}, but expected {expected}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = pd.read_csv(\"adult_with_pii.csv\", parse_dates=['DOB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (20 points)\n",
    "\n",
    "Implement a function `above_10000` that releases the **value** of the first query in a sequence of queries whose value is above 10000. Your function should have a **total** privacy cost equal to the privacy parameter $\\epsilon$ passed in when it is called.\n",
    "\n",
    "**Note**: this function (and the rest of the ones you'll define in this assignment) take a list of *query results* rather than the queries themselves (as we saw in class). This simplification makes your code a little bit simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above_10000 #1: 14976.158697205135\n",
      "above_10000 #2: 14969.10347649895\n",
      "above_10000 #3: 14921.056929301492\n"
     ]
    }
   ],
   "source": [
    "def above_10000(query_results, epsilon):\n",
    "    t_hat = 10000 + np.random.laplace(loc=0, scale=2/epsilon)\n",
    "    \n",
    "    for idx, q in enumerate(query_results):\n",
    "        noise = np.random.laplace(loc=0, scale=4/epsilon)\n",
    "        if q + noise >= t_hat:\n",
    "            return q + noise\n",
    "    \n",
    "    return -1\n",
    "\n",
    "queries = adult_data['Martial Status'].value_counts()\n",
    "print(f\"above_10000 #1: {above_10000(queries, 100)}\")\n",
    "print(f\"above_10000 #2: {above_10000(queries, 1)}\")\n",
    "print(f\"above_10000 #3: {above_10000(queries, .01)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "In 2-3 sentences, argue informally (via the definition of the sparse vector technique, post-processing, and sequential composition), that your implementation of `above_10000` has a total privacy cost of $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This algorithm has a privacy cost of $\\epsilon$: post-processing allows us to alter the data without reverting its privacy protection and we are only releasing a single index. Thus, the privacy cost is $\\epsilon$, as it is not altered by the algorithm's addition of noise and it is not increased by any other releases of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Implement a function `bounded_all_above_10000` that releases the **value** of **$c$ queries** in a sequence of queries whose value is above 10000 (where $c$ is an analyst-provided parameter limiting the number of returned results, as in the `Sparse` algorithm in Dwork & Roth). Your function should have a **total privacy cost** bounded by its parameter $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounded_all_above_10000 #1: [14975.95470694663, 10683.108689918843]\n",
      "bounded_all_above_10000 #2: [14978.959170525623, 10671.201982140936]\n",
      "bounded_all_above_10000 #3: [16028.440147448458, 10784.091575607856]\n"
     ]
    }
   ],
   "source": [
    "def bounded_all_above_10000(query_results, c, epsilon):\n",
    "    results = []\n",
    "    i = 0\n",
    "    epsilon_i = epsilon/c\n",
    "    \n",
    "    while i < len(query_results) and len(results) < c:\n",
    "        x = above_10000(query_results[i:], epsilon_i)        \n",
    "        if x == -1:\n",
    "            return results\n",
    "        else:\n",
    "            results.append(x)\n",
    "            i += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Note: the official solution also returns the total budget used\n",
    "# This will always be <= ε, but might (often is) be less than ε\n",
    "queries = list(adult_data['Martial Status'].value_counts())\n",
    "print(f\"bounded_all_above_10000 #1: {bounded_all_above_10000(queries, 3, 100)}\")\n",
    "print(f\"bounded_all_above_10000 #2: {bounded_all_above_10000(queries, 3, 1)}\")\n",
    "print(f\"bounded_all_above_10000 #3: {bounded_all_above_10000(queries, 3, .01)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "In 2-3 sentences, argue informally that your implementation of `bounded_all_above_10000` has privacy cost bounded by $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normally, because we can in the worst case scenario call `above_10000` n times (where `n = len(query_results_`), our privacy cost would be $n\\epsilon$. However, we are splitting the privacy cost for each call by using $\\epsilon_i = \\epsilon/c$, thus bounding the privacy cost to: $c\\frac{\\epsilon}{c} = \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (30 points)\n",
    "\n",
    "Implement a function `mean_age` that computes the mean age of participants in the `adult_data` dataset. Your function should have a **total** privacy cost of $\\epsilon$. It should work as follows:\n",
    "\n",
    "1. Compute an *upper* clipping parameter based on the data\n",
    "2. Compute a *lower* clipping parameter based on the data\n",
    "3. Clip the data using the lower and upper clipping parameters\n",
    "4. Use `laplace_mech` to release a differentially private mean of the clipped data\n",
    "\n",
    "*Hint*: Use the sparse vector technique to compute the clipping parameters. Consider using a sequence of queries that looks like `np.sum(clip(df, b, 0)) - np.sum(clip(df, b+1, 0))`.\n",
    "\n",
    "*Hint*: Be careful of sensitivities and set the scale of the noise accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 0.001, mean age: 54.81847089651001\n",
      "epsilon: 0.01, mean age: 39.17962688302697\n",
      "epsilon: 0.1, mean age: 38.51168278029223\n",
      "epsilon: 0.5, mean age: 38.510669957462746\n",
      "epsilon: 1, mean age: 38.59243118757453\n",
      "epsilon: 10, mean age: 38.58022182685648\n"
     ]
    }
   ],
   "source": [
    "bs = list(range(0, 200, 10))\n",
    "df = adult_data['Age']\n",
    "\n",
    "def sens_one_query(b):\n",
    "    # Return a lambda that generates a sensitivity-1 version of a query of the sum of ages in 'adult_data[Age]'\n",
    "    return lambda df: df.clip(lower=0, upper=b).sum() - df.clip(lower=0, upper=b+1).sum()\n",
    "\n",
    "def above_0(queries, epsilon):\n",
    "    # Define the noise threshold\n",
    "    t_hat = np.random.laplace(loc=0, scale = 2/epsilon)\n",
    "    \n",
    "    # If noisy query value is greater than the noisy threshold, return its index in 'queries'. \n",
    "    # This means the best value of q in queries has been identified\n",
    "    for idx, q in enumerate(queries):\n",
    "        noise = np.random.laplace(loc=0, scale = 4/epsilon)\n",
    "        if q(df) + noise >= t_hat:\n",
    "            return idx\n",
    "\n",
    "    # If no value was found, return the index of the last element in 'queries'\n",
    "    return -1 \n",
    "\n",
    "def mean_age(epsilon):\n",
    "    # Define constants\n",
    "    lower_bound = 0\n",
    "    epsilon_fraction = epsilon/3\n",
    "    \n",
    "    # Generate queries\n",
    "    sens_one_queries = [sens_one_query(b) for b in bs]\n",
    "    \n",
    "    # Determine the lowest value of upper bound b which stops increasing the values of the sens_one_queries\n",
    "    upper_bound = bs[above_0(sens_one_queries, epsilon_fraction)]\n",
    "    \n",
    "    # Return noisy mean\n",
    "    return laplace_mech(df.clip(lower=lower_bound, upper=upper_bound).sum(), upper_bound, epsilon_fraction)/laplace_mech(len(df), 1, epsilon_fraction)\n",
    "    \n",
    "for epsilon in [0.001, 0.01, 0.1, 0.5, 1, 10]:\n",
    "    print(f\"epsilon: {epsilon}, mean age: {mean_age(epsilon)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "In 3-5 sentences, describe your approach to implementing `mean_age` and argue informally that your implementation has privacy cost bounded by $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This implementation defines constants (critically, splitting the privacy budget), generates a set of sensitivity-1 queries of the sum of `adult_data[age]` which are used to determine the best clipping parameter for the data (by using `above_0`, a modified version of `above_threshold`, and, with this optimally-clipped data, calculates its mean. When designing the implementation, I referenced the notes on the use of the sparse-vector-technique and tried to understand how it is able to determine an optimal clipping parameter. This was quite confusing to me at first, but after I figured it out, the rest came naturally.\n",
    "- This implementation has a total privacy cost of $\\epsilon$ because it splits the privacy budget in thirds: one third is used to calculate the best clipping parameter, a third to determine the noisy sum of the clipped data, and a third used to calculate a noisy length of the clipped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
